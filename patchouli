#!/usr/bin/env python3
#
# /// script
# requires-python = ">=3.12"
# dependencies = ["requests>=2.32.5"]
# ///

from pathlib import Path
import re
import shutil
import requests
import argparse
import tempfile
import subprocess
import os
import mimetypes
from typing import NoReturn, TypedDict, cast, NotRequired, Optional

VERSION = "v0.1.1"
APP_NAME = "patchouli"
DEVELOPER = "Avimitin"
GITHUB = "https://github.com/Avimitin/patchouli"
UA = f"{DEVELOPER}/{APP_NAME}/{VERSION} ({GITHUB})"

API_URL = "https://api.bgm.tv"

# Constants
AUTHOR_KEYS = ["作者", "作画", "原作"]
RELATION_SINGLE_BOOKLET = "单行本"

# Compiled Regexes
# Matches: - 卷01, - Vol.01, - Vol01, - 01
# Note: The order in alternation matters if they overlap, but here they are distinct prefixes.
# We use non-capturing group (?:...) for the prefix.
# 1. 卷
# 2. Vol.
# 3. Vol
# 4. Empty (just the number)
VOL_PATTERN = re.compile(r"-\s*(?:卷|Vol\.|Vol)?\s*(\d+)", re.IGNORECASE)

# Pattern: "Name - Author [bgm_123]"
DIR_PATTERN_ID = re.compile(r"^(.*)\s-\s(.*)\s\[bgm_(\d+)\]$")
# Pattern: "Name - Author"
DIR_PATTERN_BASIC = re.compile(r"^(.*)\s-\s(.*)$")
# Validation for basic pattern to ensure it's not a malformed ID pattern
BGM_ID_VALIDATOR = re.compile(r"^(?:\[?bgm_)?\d+\]?$")


def bail(s: str, code: int = 1) -> NoReturn:
    """
    Print error message and exit with custom exit code.

    Args:
        s: The message to report.
        code: The exit code, default exit with 1.
    """
    print(f"ERROR: {s}")
    exit(code)


def cli_check(exec_name: str) -> str:
    """
    Check CLI existence and bail out when not found. Return full path to the CLI.

    Args:
        exec_name: CLI name to search in system.
    """
    path = shutil.which(exec_name)
    if path is None:
        bail(f"{exec_name} not found in system")
    return path


def guess_vol(filename: str) -> int | None:
    """
    Match volume filename with following pattern:
        * name - 卷01...
        * name - 卷 01...
        * name - Vol.01...
        * name - Vol01...
        * name - Vol 01...
        * name - 01...

    Args:
        filename: The name of the manga file, don't pass full path.
    """
    capture = VOL_PATTERN.search(filename)
    if capture is not None:
        return int(capture.group(1))
    return None


class BgmSubjectTag(TypedDict):
    name: str
    count: str


class BgmSubjectInfobox(TypedDict):
    key: str
    value: str


class BgmSubjectImages(TypedDict):
    large: str
    common: str
    medium: str
    small: str
    grid: str


class BgmSubjectResp(TypedDict):
    id: int
    series: bool
    platform: str
    date: str
    name: str
    name_cn: str
    tags: list[BgmSubjectTag]
    meta_tags: list[str]
    infobox: list[BgmSubjectInfobox]
    images: BgmSubjectImages


def get_bangumi_subject(subject_id: int) -> BgmSubjectResp:
    """
    Fetches subject details from the Bangumi API.

    Args:
        subject_id: The integer ID of the subject to fetch.
    """
    endpoint = f"/v0/subjects/{subject_id}"
    url = API_URL + endpoint
    headers = {"User-Agent": UA}

    try:
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()

        data = response.json()
        # Basic structure check to ensure we don't crash later
        if not isinstance(data, dict) or "name" not in data or "id" not in data:
            bail(f"Invalid API response for subject ID {subject_id}")

        return cast(BgmSubjectResp, data)
    except requests.exceptions.RequestException as req_err:
        bail(f"Network error occurred: {req_err}")
    except ValueError:
        bail(f"Could not decode JSON response. Send issue at {GITHUB}")


class BgmSearchResp(TypedDict):
    data: list[BgmSubjectResp]


class BgmSearchFilter(TypedDict):
    type: list[int]
    nsfw: bool


class BgmSearchPayload(TypedDict):
    keyword: str
    sort: str
    filter: BgmSearchFilter


def search_bangumi_subjects(search_payload: BgmSearchPayload) -> BgmSearchResp:
    """
    Sends a search request to the Bangumi API with a JSON payload.

    Args:
        search_payload: A dictionary containing the search criteria.
    """
    endpoint = "/v0/search/subjects"
    url = API_URL + endpoint
    headers = {"User-Agent": UA, "Content-Type": "application/json"}

    try:
        response = requests.post(url, headers=headers, json=search_payload, timeout=20)
        response.raise_for_status()

        data = response.json()
        if not isinstance(data, dict) or "data" not in data:
            bail("Invalid search API response")

        return cast(BgmSearchResp, data)
    except requests.exceptions.RequestException as req_err:
        bail(f"Network error occurred: {req_err}")
    except ValueError:
        bail(f"Could not decode JSON response from server. Send issue at {GITHUB}")


class BgmRelationResp(TypedDict):
    name: str
    relation: str
    type: int
    id: int


def get_bangumi_subject_relation(subject_id: int) -> list[BgmRelationResp]:
    """
    Fetches subject relation from the Bangumi API.

    Args:
        subject_id: The integer ID of the subject to fetch.
    """
    endpoint = f"/v0/subjects/{subject_id}/subjects"
    url = API_URL + endpoint
    headers = {"User-Agent": UA}

    try:
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()

        data = response.json()
        if not isinstance(data, list):
            bail(f"Invalid relation API response for subject ID {subject_id}")

        return cast(list[BgmRelationResp], data)
    except requests.exceptions.RequestException as req_err:
        bail(f"Network error occurred: {req_err}")
    except ValueError:
        bail(f"Could not decode JSON response. Send issue at {GITHUB}")


def get_volume_map(relations: list[BgmRelationResp]) -> dict[int, int]:
    """
    Parse relations to find single booklets (单行本) and map volume number to subject ID.
    Expected format in name: "Name (Vol)" or similar.
    """
    vol_map = {}
    for rel in relations:
        if rel["type"] == 1 and rel["relation"] == RELATION_SINGLE_BOOKLET:
            # Extract volume number from "Name (12)" or "Name (1)"
            # Matches parenthesis with number at the end of string
            match = re.search(r"\((\d+)\)$", rel["name"])
            if match:
                try:
                    vol_num = int(match.group(1))
                    vol_map[vol_num] = rel["id"]
                except ValueError:
                    pass
    return vol_map


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="A tool to bridge import Bangumi metadata to Calibre",
        prog=APP_NAME,
    )
    subparsers = parser.add_subparsers(
        dest="command", help="Available commands", required=True
    )
    addp = subparsers.add_parser("add", help="Add new manga")
    addp.add_argument("path", nargs="?", help="Path to the manga series directory")
    addp.add_argument(
        "-d",
        "--directory",
        help="Path to the directory containing multiple manga series",
    )
    addp.add_argument(
        "--prefer-cn-name",
        action="store_true",
        help="Prefer using Chinese translated name as title",
    )
    addp.add_argument(
        "--library-path",
        type=str,
        help="Path to the calibre library. Can be a remote server address (e.g., http://localhost:8080/#mylibrary)",
    )
    addp.add_argument(
        "-l",
        "--language",
        required=True,
        help="Language code for the manga (e.g., zho, jpn, eng)",
    )
    addp.add_argument(
        "--dry-run",
        action="store_true",
        help="Print job sequence instead of execute it",
    )
    addp.add_argument(
        "--query-only",
        action="store_true",
        help="Query metadata and print metadata, but don't acutally add books to Calibre",
    )

    try:
        args = parser.parse_args()
        return args
    except argparse.ArgumentError:
        parser.print_help()
        exit(0)


class CalibreAddConfig(TypedDict):
    file_path: Path

    title: str
    authors: list[str]
    isbn: NotRequired[str]
    tags: list[str]
    series: NotRequired[str]
    series_index: NotRequired[int]
    cover: NotRequired[str]
    languages: list[str]


def config_to_args(cfg: CalibreAddConfig, extra_db_args: list[str]) -> list[str]:
    args: list[str] = []
    args += ["-t", cfg["title"]]

    authors = "&".join(cfg["authors"])  # Calibre often uses & for multiple authors
    args += ["-a", authors]

    isbn = cfg.get("isbn")
    if isbn is not None:
        args += ["-i", isbn]

    tags = ",".join(cfg["tags"])
    args += ["-T", tags]

    series = cfg.get("series")
    if series is not None:
        args += ["-s", series]

    series_index = cfg.get("series_index")
    if series_index is not None:
        args += ["-S", str(series_index)]

    cover_image = cfg.get("cover")
    if cover_image is not None:
        args += ["-c", cover_image]

    languages = ",".join(cfg["languages"])
    if languages:
        args += ["-l", languages]

    return args + extra_db_args + [str(cfg["file_path"])]


def parse_dir_name(dir_name: str) -> Optional[tuple[str, str, int | None]]:
    """
    Parse directory name to extract manga name, optional author, and optional Bangumi ID.
    Patterns:
    1. "Name - Author [bgm_ID]"
    2. "Name - Author"
    """
    # Pattern 1: "Name - Author [bgm_ID]"
    match = DIR_PATTERN_ID.search(dir_name)
    if match:
        return match.group(1).strip(), match.group(2).strip(), int(match.group(3))

    # Pattern 2: "Name - Author"
    match = DIR_PATTERN_BASIC.search(dir_name)
    if match:
        # Check if the second part looks like an author, not a bgm_ID.
        # If it looks like a bgm_ID, then this pattern doesn't apply.
        potential_author_or_id = match.group(2).strip()
        if not BGM_ID_VALIDATOR.match(potential_author_or_id):
            return match.group(1).strip(), potential_author_or_id, None

    # If no valid pattern matches, return None
    return None


def download_cover(url: str) -> str | None:
    """Download cover image to a temp file and return its path."""
    if not url:
        return None
    try:
        response = requests.get(url, stream=True, timeout=20)
        response.raise_for_status()

        content_type = response.headers.get("content-type")
        if not content_type:
            # Fallback based on URL or default
            if ".png" in url:
                extension = ".png"
            else:
                extension = ".jpg"
        else:
            extension = mimetypes.guess_extension(content_type)

        fd, path = tempfile.mkstemp(suffix=extension)
        with os.fdopen(fd, "wb") as f:
            shutil.copyfileobj(response.raw, f)
        return path
    except Exception as e:
        bail(f"Failed to download cover: {e}")


def get_author(infobox: list[BgmSubjectInfobox]) -> list[str]:
    """Extract authors from infobox."""
    authors = []
    for item in infobox:
        if item["key"] in AUTHOR_KEYS:
            # Value might be "AuthorName" or "Name1, Name2"
            parts = item["value"].replace("、", ",").split(",")
            for p in parts:
                cleaned = p.strip()
                if cleaned and cleaned not in authors:
                    authors.append(cleaned)
    return authors


def resolve_subject(
    manga_name_from_dir: str, author_from_dir: str | None, bgm_id: int | None
) -> Optional[BgmSubjectResp]:
    if bgm_id:
        print(f"  Found ID in name: {bgm_id}")
        return get_bangumi_subject(bgm_id)

    search_keyword = manga_name_from_dir
    if author_from_dir:
        search_keyword = (
            f"{manga_name_from_dir} {author_from_dir}"  # Combine for better search
        )
    print(f"  Searching Bangumi for '{search_keyword}'...")
    MANGA_TYPE = 1  # 1 = book/manga
    search_res = search_bangumi_subjects(
        {
            "keyword": search_keyword,
            "sort": "match",
            "filter": {"type": [MANGA_TYPE], "nsfw": True},
        }
    )
    if search_res["data"]:
        subject = search_res["data"][0]
        print(f"  Matched: {subject['name']} (ID: {subject['id']})")
        return subject

    print(f"  No results found for '{search_keyword}', skipping.")
    return None


def process_manga_file(
    f: Path,
    subject: BgmSubjectResp,
    series_name: str,
    author_from_dir: str | None,
    volume_map: dict[int, int],
    args: argparse.Namespace,
    calibre_exec: str,
    global_calibre_args: list[str],
):
    vol_idx = guess_vol(f.name)

    current_subject = subject  # Default to series subject

    # Check if we have specific volume metadata
    if vol_idx is not None and vol_idx in volume_map:
        print(
            f"  Fetching specific metadata for Volume {vol_idx} (ID: {volume_map[vol_idx]})..."
        )
        current_subject = get_bangumi_subject(volume_map[vol_idx])

    # Prepare metadata
    title = current_subject["name"]
    if args.prefer_cn_name and current_subject.get("name_cn"):
        title = current_subject["name_cn"]

    authors = []
    if author_from_dir:  # Prioritize author from directory name
        authors.append(author_from_dir)
    else:  # Fallback to authors from Bangumi metadata
        authors.extend(get_author(current_subject.get("infobox", [])))

    if not authors:
        authors = ["Unknown"]

    tags = [t["name"] for t in current_subject.get("tags", [])]

    cover_url = current_subject.get("images", {}).get("large")
    cover_path = None

    if not args.query_only:
        if vol_idx is not None:
            cover_path = download_cover(cover_url)

    if args.query_only:
        print(f"  [Query Only] Metadata for {f.name}:")
        print(f"    Title: {title}")
        print(f"    Series: {series_name}")  # Series should keep the main series name
        print(f"    Authors: {authors}")
        print(f"    Tags: {tags}")
        print(f"    Date: {current_subject.get('date')}")
        print(
            f"    Cover: {cover_url if vol_idx is not None else 'None (Skipped due to missing volume index)'}"
        )
        return

    cfg: CalibreAddConfig = {
        "file_path": f,
        "title": title,
        "authors": authors,
        "tags": tags,
        "series": series_name,  # Always use the main series name for grouping
        "languages": [args.language],
    }

    if vol_idx is not None:
        cfg["series_index"] = vol_idx

    if cover_path:
        cfg["cover"] = cover_path

    cmd_args = config_to_args(cfg, [])
    # Add -m new_record to handle duplicates for series
    full_cmd = (
        [calibre_exec] + global_calibre_args + ["add", "-m", "new_record"] + cmd_args
    )

    pub_date = current_subject.get("date")

    if args.dry_run:
        print(f"  [Dry Run] Exec: {' '.join(full_cmd)}")
        if pub_date:
            print(
                f"  [Dry Run] Exec: {calibre_exec} {' '.join(global_calibre_args)} set_metadata <ID> --field pubdate:{pub_date}"
            )
    else:
        print(f"  Adding file: {f.name}")
        try:
            # Capture output to extract the new book ID
            result = subprocess.run(
                full_cmd, check=True, capture_output=True, text=True
            )
            print(result.stdout, end="")  # Pass through stdout

            # Parse the new book ID
            # Output format: "Added book ids: 123"
            match = re.search(r"Added book ids:\s*(\d+)", result.stdout)
            if match and pub_date:
                book_id = match.group(1)
                print(f"  Setting pubdate to {pub_date} for book ID {book_id}...")
                set_meta_cmd = (
                    [calibre_exec]
                    + global_calibre_args
                    + ["set_metadata", str(book_id), "--field", f"pubdate:{pub_date}"]
                )
                subprocess.run(set_meta_cmd, check=True)

        except subprocess.CalledProcessError as e:
            bail(f"Error adding {f.name}: {e}\nStdout: {e.stdout}\nStderr: {e.stderr}")

    if cover_path and os.path.exists(cover_path):
        os.remove(cover_path)


def process_directory(
    item: Path,
    args: argparse.Namespace,
    calibre_exec: str,
    global_calibre_args: list[str],
):
    dir_name = item.name
    # Skip hidden folders
    if dir_name.startswith("."):
        return

    parsed = parse_dir_name(dir_name)

    if parsed is None:
        print(f"Skipping '{dir_name}' as it does not match expected naming patterns.")
        return

    manga_name_from_dir, author_from_dir, bgm_id = parsed

    print(f"Processing: {manga_name_from_dir}")

    subject = resolve_subject(manga_name_from_dir, author_from_dir, bgm_id)
    if not subject:
        return

    # Fetch relations to find volume specific data
    print(f"  Fetching relations for '{subject['name']}'...")
    relations = get_bangumi_subject_relation(subject["id"])
    volume_map = get_volume_map(relations)
    if volume_map:
        print(f"  Found {len(volume_map)} volume entries.")

    # Base metadata (Series level)
    series_name = subject["name"]
    if args.prefer_cn_name and subject.get("name_cn"):
        series_name = subject["name_cn"]

    # Scan files in directory
    manga_files = sorted(
        [f for f in item.iterdir() if f.is_file() and not f.name.startswith(".")]
    )

    for f in manga_files:
        process_manga_file(
            f,
            subject,
            series_name,
            author_from_dir,
            volume_map,
            args,
            calibre_exec,
            global_calibre_args,
        )


def run_add(args: argparse.Namespace):
    calibre_exec = "calibredb"
    if not args.dry_run and not args.query_only:
        cli_check(calibre_exec)

    # Prepare global calibre-db arguments
    global_calibre_args = []
    if args.library_path:
        global_calibre_args.extend(["--library-path", args.library_path])

    if args.path:
        # Process single series
        series_path = Path(args.path).resolve()
        if not series_path.exists() or not series_path.is_dir():
            bail(f"Directory not found: {series_path}")
        process_directory(series_path, args, calibre_exec, global_calibre_args)
    elif args.directory:
        # Process collection
        root_path = Path(args.directory).resolve()
        if not root_path.exists() or not root_path.is_dir():
            bail(f"Directory not found: {root_path}")

        for item in root_path.iterdir():
            if not item.is_dir():
                continue
            process_directory(item, args, calibre_exec, global_calibre_args)
    else:
        bail(
            "Please provide a series path or use -d to specify a collection directory."
        )

    print("Done.")


if __name__ == "__main__":
    args = parse_args()
    if args.command == "add":
        run_add(args)
    else:
        bail("internal error: unreachable")
